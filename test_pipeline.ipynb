{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2edd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f00fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 16:49:19.710681: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 16:49:21.005573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-30 16:49:24.749995: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cbf6a2316148a2b57e8d0dd07ddfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b9ca0a855e4019b3639d2738193c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, AutoConfig, GenerationConfig\n",
    "from FastDLLM_inferencing.Fast_dLLM_v2_7B.modeling import Fast_dLLM_QwenForCausalLM\n",
    "\n",
    "\n",
    "# load LLaDa\n",
    "device = 'cuda'\n",
    "verifier = AutoModel.from_pretrained('GSAI-ML/LLaDA-8B-Instruct', trust_remote_code=True, dtype=torch.bfloat16)\n",
    "verifier_tokenizer = AutoTokenizer.from_pretrained('GSAI-ML/LLaDA-8B-Instruct', trust_remote_code=True)\n",
    "\n",
    "\n",
    "# load fast dLLM\n",
    "model_name = \"Efficient-Large-Model/Fast_dLLM_7B\"\n",
    "\n",
    "drafter_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# remote config (no remote code execution)\n",
    "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# using local class to load remote weights\n",
    "drafter = Fast_dLLM_QwenForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    config=config, \n",
    "    trust_remote_code=True,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\",)  # downloads weights from Hub\n",
    "\n",
    "# (optional) generation parameters from the repo\n",
    "gen_config = GenerationConfig.from_pretrained(model_name)\n",
    "drafter.generation_config = gen_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4fea71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fast_dLLM_QwenForCausalLM(\n",
       "  (model): Fast_dLLM_QwenModel(\n",
       "    (embed_tokens): Embedding(152064, 3584, padding_idx=151645)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Fast_dLLM_QwenDecoderLayer(\n",
       "        (self_attn): Fast_dLLM_QwenAttention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Fast_dLLM_QwenMLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Fast_dLLM_QwenRMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Fast_dLLM_QwenRMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Fast_dLLM_QwenRMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Fast_dLLM_QwenRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure everything is on device\n",
    "verifier.to(device)\n",
    "drafter.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29a6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model wrapper functions for Fast_dLLM and LLaDA\n",
    "# Add this to your notebook or create a new file: model_wrappers.py\n",
    "\n",
    "import torch\n",
    "from LLaDA.generate import generate_per_step\n",
    "\n",
    "\n",
    "def fastdllm_generate_fn(model, tokenizer, input_ids, num_steps, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper for Fast_dLLM generation to match pipeline interface.\n",
    "    \n",
    "    Args:\n",
    "        model: Fast_dLLM model\n",
    "        tokenizer: Fast_dLLM tokenizer\n",
    "        input_ids: Input tensor\n",
    "        num_steps: Number of steps\n",
    "        **kwargs: Additional arguments (small_block_size, threshold, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Generated tensor\n",
    "    \"\"\"\n",
    "    # Extract Fast_dLLM specific parameters or use defaults\n",
    "    small_block_size = kwargs.get('small_block_size', 8)\n",
    "    threshold = kwargs.get('threshold', 0.95)\n",
    "    max_new_tokens = kwargs.get('max_new_tokens', 256)\n",
    "    \n",
    "    # Fast_dLLM returns (gen_ids, past_key_values, past_block_key_values)\n",
    "    gen_ids, kv_cache, block_kv_cache = model.generate(\n",
    "        input_ids,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        small_block_size=small_block_size,\n",
    "        threshold=threshold,\n",
    "        steps=num_steps,\n",
    "    )\n",
    "    \n",
    "    return gen_ids, kv_cache, block_kv_cache\n",
    "\n",
    "\n",
    "def llada_generate_fn(model, tokenizer, input_ids, num_steps, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper for LLaDA generation to match pipeline interface.\n",
    "    \n",
    "    Args:\n",
    "        model: LLaDA model\n",
    "        tokenizer: LLaDA tokenizer\n",
    "        input_ids: Input tensor (should already have prompt + masked tokens)\n",
    "        num_steps: Number of steps (n)\n",
    "        **kwargs: Additional arguments (k, gen_length, block_length, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Generated tensor\n",
    "    \"\"\"\n",
    "    # Extract LLaDA specific parameters\n",
    "    k = kwargs.get('k', 1)  # tokens per step\n",
    "    gen_length = kwargs.get('gen_length', 256)\n",
    "    block_length = kwargs.get('block_length', 256)\n",
    "    temperature = kwargs.get('temperature', 0.0)\n",
    "    remasking = kwargs.get('remasking', 'low_confidence')\n",
    "    mask_id = kwargs.get('mask_id', 126336)\n",
    "    \n",
    "    # LLaDA's generate_per_step expects just the prompt, not prompt+masked\n",
    "    # So we need to extract the prompt part\n",
    "    # Assuming the masked tokens are at the end\n",
    "    mask_positions = (input_ids == mask_id)\n",
    "    if mask_positions.any():\n",
    "        # Find first masked position\n",
    "        first_mask_idx = torch.where(mask_positions[0])[0][0].item()\n",
    "        prompt = input_ids[:, :first_mask_idx]\n",
    "    else:\n",
    "        # No masks, use entire input as prompt\n",
    "        prompt = input_ids\n",
    "    \n",
    "    output = generate_per_step(\n",
    "        model,\n",
    "        prompt,\n",
    "        n=num_steps,\n",
    "        k=k,\n",
    "        gen_length=gen_length,\n",
    "        block_length=block_length,\n",
    "        temperature=temperature,\n",
    "        remasking=remasking,\n",
    "        mask_id=mask_id\n",
    "    )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9edf27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full decoded base prompt (with special tokens):\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a short introduction to large language models.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "|<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>|\n",
      "###############################################\n",
      "Full decoded for drafter step 16 (with special tokens):\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a short introduction to large language models.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to|<MASK>| and generate human-like|<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>|\n",
      "###############################################\n",
      "Conversion: 227 tokens -> 227 tokens\n",
      "Full decoded for conversion (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to<|mdm_mask|> and generate human-like<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|>\n",
      "###############################################\n",
      "Full decoded for verfier step 1 (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|endoftext|>\n",
      "Conversion: 270 tokens -> 269 tokens\n",
      "Warning: Length mismatch. Drafter: 256, Verifier(conv): 298. Truncating to 256.\n",
      "Iteration 1: Truncated to length 43 due to masks.\n",
      "Full decoded for drafter step 32 (with special tokens):\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a short introduction to large language models.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data,|<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>|\n",
      "###############################################\n",
      "Conversion: 259 tokens -> 259 tokens\n",
      "Full decoded for conversion (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data,<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|>\n",
      "###############################################\n",
      "Full decoded for verfier step 2 (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data,<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|endoftext|>\n",
      "Conversion: 287 tokens -> 286 tokens\n",
      "Warning: Length mismatch. Drafter: 288, Verifier(conv): 315. Truncating to 288.\n",
      "Iteration 2: Truncated to length 60 due to masks.\n",
      "Full decoded for drafter step 48 (with special tokens):\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a short introduction to large language models.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and|<MASK>|.|<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>|\n",
      "###############################################\n",
      "Conversion: 259 tokens -> 259 tokens\n",
      "Full decoded for conversion (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and<|mdm_mask|>.<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|>\n",
      "###############################################\n",
      "Full decoded for verfier step 3 (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|endoftext|>\n",
      "Conversion: 304 tokens -> 303 tokens\n",
      "Warning: Length mismatch. Drafter: 288, Verifier(conv): 332. Truncating to 288.\n",
      "Iteration 3: Truncated to length 77 due to masks.\n",
      "Full decoded for drafter step 64 (with special tokens):\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a short introduction to large language models.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and sentences. LLMs can perform various natural language processing tasks, such as language translation, text summar|<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>||<MASK>|\n",
      "###############################################\n",
      "Conversion: 291 tokens -> 290 tokens\n",
      "Full decoded for conversion (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and sentences. LLMs can perform various natural language processing tasks, such as language translation, text summar<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|>\n",
      "###############################################\n",
      "Full decoded for verfier step 4 (with special tokens):\n",
      "<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a short introduction to large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and sentences. LLMs can perform various natural language processing tasks, such as language translation, text summar<|mdm_mask|>,<|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|><|mdm_mask|>\n",
      "Conversion: 323 tokens -> 324 tokens\n",
      "Warning: Length mismatch. Drafter: 320, Verifier(conv): 353. Truncating to 320.\n",
      "Generated text:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Give me a short introduction to large language models.\n",
      "assistant\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained on massive datasets of text data, enabling them to learn intricate patterns, structures, and relationships between words, phrases, and sentences. LLMs can perform various natural language processing tasks, such as language translation, text summar,\n",
      "\n",
      "Stats:\n",
      "{'iterations': 4, 'total_drafter_steps': 64, 'total_verifier_steps': 4, 'tokens_remasked_per_iteration': [0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from dual_pipeline import dual_diffusion_generate\n",
    "from inference import convert\n",
    "\n",
    "result = dual_diffusion_generate(\n",
    "    # Models\n",
    "    drafter_model=drafter,\n",
    "    drafter_tokenizer=drafter_tokenizer,\n",
    "    verifier_model=verifier,\n",
    "    verifier_tokenizer=verifier_tokenizer,\n",
    "    \n",
    "    # Input\n",
    "    query=\"Give me a short introduction to large language models.\",\n",
    "    max_new_tokens=256,\n",
    "    \n",
    "    # Steps\n",
    "    num_drafter_steps=16,\n",
    "    num_verifier_steps=1,\n",
    "    \n",
    "    # Mask IDs\n",
    "    drafter_mask_id=151665,  # Fast_dLLM mask ID\n",
    "    verifier_mask_id=126336,  # LLaDA mask ID\n",
    "    \n",
    "    # Custom generate functions\n",
    "    drafter_generate_fn=fastdllm_generate_fn,\n",
    "    verifier_generate_fn=llada_generate_fn,\n",
    "    \n",
    "    # Verification (None = use default trust_verifier)\n",
    "    verification_fn=None,\n",
    "    \n",
    "    # Iteration control\n",
    "    max_iterations=4,  # Single draft-verify pass\n",
    "    \n",
    "    # Model-specific kwargs\n",
    "    small_block_size=8,\n",
    "    threshold=0.95,\n",
    "    k=1,\n",
    "    gen_length=256,\n",
    "    block_length=256,\n",
    "    temperature=0.0,\n",
    "    remasking='low_confidence'\n",
    ")\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(result['output_text'])\n",
    "print(\"\\nStats:\")\n",
    "print(result['stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d210444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
